{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "diverse-motion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-hobby",
   "metadata": {},
   "source": [
    "# 학습목표\n",
    "\n",
    "- 레이어의 개념을 이해한다.\n",
    "\n",
    "\n",
    "- 딥러닝 모델 속 각 레이어(Linear, Convolution)의 동작 방식을 이해한다.\n",
    "\n",
    "\n",
    "- 데이터의 특성을 고려한 레이어를 설계하고, 이를 Tensorflow로 정의하는 법을 배운다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-plant",
   "metadata": {},
   "source": [
    "많은 사람들이 인공지능이나 딥러닝 공부를 하고 있습니다.\n",
    "\n",
    "누구는 통계나 수학을 열심히공부할 것 이고, 누구는 예제코드를 따라치며 인공 신경망 네트워크 (Artificial Neural network(Ann)이하 신경망)설계의 감을 익히고 있습니다.\n",
    "\n",
    "전자와 후자를 모두 공부했다고 둘 사이의 미싱링크(missing link)를 느껴보셨을 겁니다.\n",
    "\n",
    "딥러닝은 y = Wx + by = Wx + b 에서 최적의 WW(Weight)과 bb를 찾는 과정!\n",
    "\n",
    "많은 사람들이 딥러닝을 공부하고 있습니다. 어느 누구는 통계나 수학을 열심히 공부하고 있을 것이고, 어느 누구는 수많은 예제 코드를 따라치며 인공 신경망 네트워크(Artificial Neural Network(ANN), 이하 신경망) 설계의 감을 익히고 있겠죠. 전자와 후자를 모두 지나왔다면, 둘 사이의 미싱 링크(missing link) 를 느껴보셨을 겁니다.\n",
    "\n",
    "딥러닝은 y = Wx + by=Wx+b 에서 최적의 WW(Weight)과 bb를 찾는 과정!\n",
    "\n",
    "들어본 적 있는 문장인가요? \n",
    "\n",
    "하지만 막상 이를 누군가에게 설명하려고 하면 쉽지 않을 겁니다.\n",
    "\n",
    "저는 이를 딥러닝의 미싱 링크라 칭합니다. \n",
    "\n",
    "우리가 정의하는 수많은 신경망들은 각기 다른 형태의 Weight를 갖고 있고, 그마다 독특한 특성을 가지고 있습니다.\n",
    "\n",
    "데이터에서 원하는 특징을 효과적으로 추출하기 위해선 올바른 Weight를 정의하는 과정이 중요합니다.\n",
    "\n",
    "그리고 그 과정은 하나의 직관이 되어 신경망을 분석하거나 설계하는 데에 큰 도움이 될 것입니다.\n",
    "\n",
    "우리는 데이터의 차원 변화를 좇으며 각기 다른 신경망들이 갖는 Weight의 특성을 살펴보고, 앞서 언급한 미싱 링크의 진정한 의미를 두 번에 걸쳐 알아볼 예정입니다. \n",
    "\n",
    "이번 시간에서는 Linear 레이어와 Convolution 레이어를 집중적으로 공부하고, 다음번에는 Embedding 레이어와 Recurrent 레이어를 다루어 볼 것입니다.\n",
    "이 과정을 통해 데이터의 차원 변화를 좇아 여러 신경망들이 갖는 Weight의 특성을 살펴보면서, 앞서 언급한 미싱 링크의 진정한 의미를 깨닫게 되기를 기대합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-prior",
   "metadata": {},
   "source": [
    "딥러닝을 이해하는 방법 중 가장 쉬운 방법은 데이터의 형태변화를 좇는 것 입니다.\n",
    "\n",
    "10개 단어의 문장을 1) 5개 단어로 요약했다면 그것은 정보를 집약시킨 경우일 것이고, 2) 20개 단어로 확장했다면 그것은 정보를 더 세밀하게 표현한 경우겠죠?\n",
    "\n",
    "아래는 기업 A에 지원한 지원자들의 인적 사항입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-motion",
   "metadata": {},
   "source": [
    "![title](https://d3s0tskafalll9.cloudfront.net/media/images/F-24-2.max-800x600.png)\n",
    "\n",
    "위 표의 데이터는 (3, 6)의 매트릭스로 표현 가능합니다.\n",
    "\n",
    "만약 기업B의 데이터가 추가된다 어떻게 될까요?\n",
    "\n",
    "![title](https://d3s0tskafalll9.cloudfront.net/media/images/F-24-3.max-800x600.png)\n",
    "\n",
    "위에 표의 데이터는 (2, 3, 6)의 매트릭스로 표현이 가능합니다.\n",
    "\n",
    "이미지 데이터는 보통 채널(Channel) 이라는 것을 가집니다. 우리가 일상적으로 사용하는 것은 대부분 RGB 이미지인데요, 여기서 RGB는 Red 채널, Green 채널, 그리고 Blue 채널까지 총 3개의 채널을 의미합니다. 아래와 같은 분위기의 사진을 혹시 보신 적이 있나요?\n",
    "\n",
    "![title](https://d3s0tskafalll9.cloudfront.net/media/images/F-24-red.max-800x600.png)\n",
    "\n",
    "위 이미지가 바로 3개의 채널 중 Red 채널만을 나타낸 이미지랍니다. 같은 맥락으로 Green 채널과 Blue 채널도 추출할 수 있고, 모든 채널을 한 데 겹치면 우리 눈에 익숙한 RGB 이미지가 되죠!\n",
    "\n",
    "![title](https://d3s0tskafalll9.cloudfront.net/media/images/F-24-allcolor.max-800x600.png)\n",
    "![title](https://d3s0tskafalll9.cloudfront.net/media/images/F-24-4.max-800x600.png)\n",
    "\n",
    "RGB 이미지라고 가정을 한다면, 위 그림의 데이터는 (3, 1920, 1080) 또는 (1920, 1080, 3) 의 매트릭스로 표현이 가능합니다. 그리고 표현 방식에 따라 Channel, Width, Height의 이니셜로 (C, W, H), (W, H, C)와 같이 표기합니다. 이 표기법을 알고 있다면, 어떤 딥러닝 모듈이 요구하는 데이터 형태를 알아보고 그에 맞게 데이터를 변형시킬 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-emerald",
   "metadata": {},
   "source": [
    "## 문제\n",
    "\n",
    "### Q1. 해상도가 1280 x 1024(30fps)이고 러닝타임(T)이 90분인 흑백 영화 데이터는 어떻게 표현할 수 있을까요? 표기는 (T, C, H, W)를 따라주세요.\n",
    "\n",
    "A : (162000, 1, 1024, 1280)\n",
    "\n",
    "    Time: 90분 x 60초 x 30fps Channel: 흑백 영화는 단일 채널로 이루어진다. Height: 1024 Width: 1280"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-invention",
   "metadata": {},
   "source": [
    "레이어(layer) 라는 단어는 제법 많은 곳에서 쓰이고 있습니다. 통신을 공부하셨다면 OSI 7 레이어를 들어보셨을 것이고, 포토샵에서도 레이어가 쓰이며, 심지어 레이어드 패션이 유행한 적도 있었죠. \n",
    "\n",
    "약간씩 다른 의미로 사용되고 있는 용어지만, 우리가 이해해야 할 개념에 가장 가까운 정의는 다음과 같습니다.\n",
    "\n",
    "        - 하나의 물체가 여러 개의 논리적인 객체들로 구성되어 있는 경우, 이러한 각각의 객체를 하나의 레이어라 한다.\n",
    "        \n",
    "신경망이라는 물체를 구성하는 여러 개의 논리적인 레이어들을 이해하는 것은 곧 신경망 그 자체를 이해하는 것과 같죠.\n",
    "\n",
    "서론의 Weight 얘기를 기억하나요? 신경망의 Weight라고 표현했지만, 정확히는 레이어의 Weight가 맞습니다.\n",
    "\n",
    "신경망은 레이어들의 각기 다른 Weight, 그것들이 유기적으로 연결되어 이뤄내는 하나의 결과물인 것이죠.\n",
    "\n",
    "그것은 마치 인간의 두뇌와 닮아서 인공 신경망이라는 이름을 갖게 됩니다.\n",
    "\n",
    "![title](https://d3s0tskafalll9.cloudfront.net/media/images/F-24-5.max-800x600.png)\n",
    "\n",
    "이제 각각의 레이어가 어떤 특징을 가지며, 어떻게 쓰이면 좋은지 알아보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-prescription",
   "metadata": {},
   "source": [
    "Fully Connected Layer, Feedforward Neural Network, Multilayer Perceptrons, Dense Layer... 등 다양한 이름으로 불리지만 그 모든 것들은 결국 Linear 레이어에 해당하며 그런 이유에서 필자는 Linear 레이어라고 칭하는 것을 선호합니다.\n",
    "\n",
    "선형대수학에서 쓰이는 용어 중 선형 변환(Linear Transform)이 있는데, 그것과 완전히 동일한 기능을 하는 레이어입니다. \n",
    "\n",
    "선형변환이 낯선 분은 아래 영상을 참고하시면 도움이 되실 겁니다.\n",
    "\n",
    "자세하고 수학적인 이해를 원하는 분은 밑에 참고영상을 참고해주시기 바랍니다.\n",
    "[참고영상](https://www.youtube.com/watch?v=kYB8IZa5cAuE)\n",
    "\n",
    "쉽고 직관적인 이해를 원하시는 분은 밑 참고영상을 참고해주시기 바랍니다.\n",
    "[참고영상](https://www.youtube.com/watch?v=vVvjYzFBUVk)\n",
    "\n",
    "Linear 레이어는 선형 변환을 활용해 데이터를 특정 차원으로 변환하는 기능을 합니다. \n",
    "\n",
    "100차원의 데이터를 300차원으로 변환한다면 데이터를 더 풍부하게 표현하는 효과가 있고, 반대로 10차원의 데이터로 변환한다면 데이터를 집약시키는 효과가 있습니다. \n",
    "\n",
    "![title](https://d3s0tskafalll9.cloudfront.net/media/images/F-24-6.max-800x600.png)\n",
    "\n",
    "\n",
    "위 그림의 두 사각형은 모두 (x, y) 2차원의 점 4개로 표현 가능하므로, 각각 (4, 2) 행렬 형태의 데이터로 표현할 수 있습니다. \n",
    "\n",
    "우리는 두 사각형을 각각 어떤 하나의 정수로 표현하고자 합니다. 실은 이 정수는 우리가 구분하고자 하는 사각형의 종류(class)를 의미합니다. 이를 위해, 데이터를 어떻게 집약시킬지 구상해보겠습니다.\n",
    "\n",
    "- ◎ 여기서부터는 (a, b) 와 (a x b) 는 모두 같은 형태의 행렬이라고 생각해주세요!\n",
    "\n",
    "    <식1>\n",
    "    1단계: (4, 2) x (2, 1) 행렬 = (4, )\n",
    "    2단계: (4, ) x (4, 1) 행렬 = (1, )\n",
    "    \n",
    "위 단계를 사용하면 각각의 사각형을, 정보가 집약된 하나의 정수로 표현할 수 있습니다.\n",
    "\n",
    "2차원을 1차원으로 변환하는 데에 (2, 1) 혹은 (2 x 1) 행렬이 하나 선언되고, 4차원을 1차원으로 변환하는 데에 (4, 1) 혹은 (4 x 1) 행렬이 하나 선언됨에 유의합시다. 여기서 각각의 행렬들이 Weight입니다. \n",
    "\n",
    "Linear 레이어는 (입력의 차원, 출력의 차원)에 해당하는 Weight를 가지는 특성을 가지고 있습니다.\n",
    "\n",
    "이 과정을 코드로 표현하면 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "industrial-participant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1단계 연산 준비: (64, 4, 2)\n",
      "1단계 연산 결과: (64, 4)\n",
      "1단계 Linear Layer의 Weight 형태: (2, 1)\n",
      "\n",
      "2단계 연산 준비: (64, 4)\n",
      "2단계 연산 결과: (64,)\n",
      "2단계 Linear Layer의 Weight 형태: (4, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 64\n",
    "boxes = tf.zeros((batch_size, 4, 2))     # Tensorflow는 Batch를 기반으로 동작하기에,\n",
    "                                         # 우리는 사각형 2개 세트를 batch_size개만큼\n",
    "                                         # 만든 후 처리를 하게 됩니다.\n",
    "print(\"1단계 연산 준비:\", boxes.shape)\n",
    "\n",
    "first_linear = tf.keras.layers.Dense(units=1, use_bias=False) \n",
    "# units은 출력 차원 수를 의미합니다.\n",
    "# Weight 행렬 속 실수를 인간의 뇌 속 하나의 뉴런 '유닛' 취급을 하는 거죠!\n",
    "\n",
    "first_out = first_linear(boxes)\n",
    "first_out = tf.squeeze(first_out, axis=-1) # (4, 1)을 (4,)로 변환해줍니다.\n",
    "                                           # (불필요한 차원 축소)\n",
    "\n",
    "print(\"1단계 연산 결과:\", first_out.shape)\n",
    "print(\"1단계 Linear Layer의 Weight 형태:\", first_linear.weights[0].shape)\n",
    "\n",
    "print(\"\\n2단계 연산 준비:\", first_out.shape)\n",
    "\n",
    "second_linear = tf.keras.layers.Dense(units=1, use_bias=False)\n",
    "second_out = second_linear(first_out)\n",
    "second_out = tf.squeeze(second_out, axis=-1)\n",
    "\n",
    "print(\"2단계 연산 결과:\", second_out.shape)\n",
    "print(\"2단계 Linear Layer의 Weight 형태:\", second_linear.weights[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-residence",
   "metadata": {},
   "source": [
    "![title](https://d3s0tskafalll9.cloudfront.net/media/images/F-24-7.max-800x600.png)\n",
    "\n",
    "하지만 순탄치 않습니다. 위 그림을 보니 두 사각형에 대해 1단계를 거치고 난 결과가 동일하군요.\n",
    "\n",
    "이렇게 되면 <식 1>의 2단계 입력이 동일해지니 두 번째 (4 x 1) Weight를 거치는 것이 의미가 없어집니다. \n",
    "\n",
    "여기서 모든 Weight의 모든 요소를 Parameter라고 합니다. 총 6개 (위 그림에서는 2개)의 Parameter로 이 문제를 해결하기엔 역부족이었던 것 같습니다.\n",
    "\n",
    "첫 번째 접근은 데이터를 집약하는 데에만 집중했으니, 이번엔 데이터를 더 풍부하게 만들어 봅시다.\n",
    "\n",
    "<식2>\n",
    "1단계: (4, 2) x (2 x 3) 행렬 = (4, 3)\n",
    "2단계: (4, 3) x (3 x 1) 행렬 = (4, )\n",
    "3단계: (4, ) x (4 x 1) 행렬 = (1, )\n",
    "\n",
    "![title](https://d3s0tskafalll9.cloudfront.net/media/images/F-24-8.max-800x600.png)\n",
    "\n",
    "1단계의 결과로 각 사각형에 대해 독립적인 정보가 생겨나기 시작합니다.\n",
    "\n",
    "예컨대 <식 2>는 첫 번째 접근에 비해 더 많은 사각형을 구분해낼 수 있을 것 같군요!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-ukraine",
   "metadata": {},
   "source": [
    "## 문제\n",
    "\n",
    "### Q2. <식 2>에서는 총 몇 개의 Parameter가 사용되었나요? \n",
    "\n",
    "A ) 13개.\n",
    "\n",
    "    1단계에서 2 x 3 = 6, 2단계에서 3 x 1 = 3, 3단계에서 4 x 1 = 4,\n",
    "\n",
    "    총 6 + 3 + 4 = 13개의 Parameter가 사용되었다.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-upset",
   "metadata": {},
   "source": [
    "<식 1>의 과정을 코드로 작성했던 것처럼, 이번에는 <식 2>의 과정을 Tensorflow 코드로 작성해 봅시다.\n",
    "\n",
    "작성하며 데이터 차원의 변화와 각 Weight의 형태를 확인하고, tf.keras.layers.Layer.count_params() 함수를 인터넷에서 찾아본 후 활용하여 총 parameter 개수가 Q2의 정답과 일치하는지 체크해 보세요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wrapped-upset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1단계 연산 준비: (64, 4, 2)\n",
      "1단계 연산 결과: (64, 4, 3)\n",
      "1단계 Linear Layer의 Weight 형태: (2, 3)\n",
      "\n",
      "2단계 연산 준비: (64, 4, 3)\n",
      "2단계 연산 결과: (64, 4)\n",
      "2단계 Linear Layer의 Weight 형태: (3, 1)\n",
      "\n",
      "3단계 연산 준비: (64, 4)\n",
      "3단계 연산 결과: (64,)\n",
      "3단계 Linear Layer의 Weight 형태: (4, 1)\n",
      "총 Parameters: 13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 64\n",
    "boxes = tf.zeros((batch_size, 4, 2))\n",
    "\n",
    "print(\"1단계 연산 준비:\", boxes.shape)\n",
    "\n",
    "first_linear = tf.keras.layers.Dense(units=3, use_bias=False)\n",
    "first_out = first_linear(boxes)\n",
    "\n",
    "print(\"1단계 연산 결과:\", first_out.shape)\n",
    "print(\"1단계 Linear Layer의 Weight 형태:\", first_linear.weights[0].shape)\n",
    "\n",
    "print(\"\\n2단계 연산 준비:\", first_out.shape)\n",
    "\n",
    "second_linear = tf.keras.layers.Dense(units=1, use_bias=False)\n",
    "second_out = second_linear(first_out)\n",
    "second_out = tf.squeeze(second_out, axis=-1)\n",
    "\n",
    "print(\"2단계 연산 결과:\", second_out.shape)\n",
    "print(\"2단계 Linear Layer의 Weight 형태:\", second_linear.weights[0].shape)\n",
    "\n",
    "print(\"\\n3단계 연산 준비:\", second_out.shape)\n",
    "\n",
    "third_linear = tf.keras.layers.Dense(units=1, use_bias=False)\n",
    "third_out = third_linear(second_out)\n",
    "third_out = tf.squeeze(third_out, axis=-1)\n",
    "\n",
    "print(\"3단계 연산 결과:\", third_out.shape)\n",
    "print(\"3단계 Linear Layer의 Weight 형태:\", third_linear.weights[0].shape)\n",
    "\n",
    "total_params = \\\n",
    "first_linear.count_params() + \\\n",
    "second_linear.count_params() + \\\n",
    "third_linear.count_params()\n",
    "\n",
    "print(\"총 Parameters:\", total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-awareness",
   "metadata": {},
   "source": [
    "\"그렇다면 Parameter가 많은 것이 최고인가요?\" 라고 물을 수 있습니다. 정답은 그렇지 않습니다. 지나치게 많은 Parameter는 과적합(Overfitting) 을 야기합니다. \n",
    "\n",
    "과적합은 쉽게 말하면 학생이 문제만 보고 정답을 외우는 것과 같습니다. 정답만 외운 학생은 실제 시험에서 좋은 성적을 거둘 수 없겠죠.\n",
    "\n",
    "여러분이 이런 방법들로 Weight의 형태만 선언해주면 그 파라미터 값을 임의의 실수가 채우고, 수많은 데이터를 거치며 가장 적합한 Weight를 알아서 찾아가는 과정이 바로 훈련(Training) 입니다.\n",
    "\n",
    "적합한 파라미터라는 것은 주어진 데이터가 가지는 분포에 따라 결정됩니다: 뉴스 데이터를 학습한 인공지능이 소설을 잘 쓰리라 기대할 수는 없죠. 따라서 다양한 데이터가 많으면 많을수록 실제 세계에 가까운 인공지능이 만들어지게 됩니다. \"바야흐로 빅데이터 시대\" 라는 말이 와닿는 대목이죠!\n",
    "\n",
    "#### 추가로 이야기할 것은 바로 편향(Bias) 입니다. \n",
    "\n",
    "웃어른을 만났을 때에 우리는 배꼽 인사를 하며 \"안녕하세요~\" 라고 하겠지만 프랑스에서 배꼽 인사와 \"봉주르~\"를 하는 것은 상상이 가지 않습니다...\n",
    "\n",
    "이때 인사라는 행위를 y = wxy=wx 라 한다면 우리나라의 인사법을 y = wx +y=wx+ 유교사상 , 프랑스의 인사법을 y = wx +y=wx+ 아메리칸 마인드라고 표현해 보면 어떨까요? 각 문화에 편향되었음을 보여주는 거죠! 아래 그림을 볼까요?\n",
    "\n",
    "![title](https://d3s0tskafalll9.cloudfront.net/media/images/F-24_bias_graph.max-800x600.png)\n",
    "\n",
    "두 데이터가 비슷하게 생겼지만, 원점을 건들지 않고 둘을 일치시키기는 어려워 보이죠? \n",
    "\n",
    "편향이 없다면 파라미터를 아무리 돌리고 늘리고 해도 정확하게 근사할 수 없음을 보여주는 예입니다.\n",
    "\n",
    "단순히 생각해서 원점을 평행이동하는 것만으로도 해결할 수 있기 때문에 실제로 편향은 선형변환된 값에 편향 파라미터 b를 더해주는 것으로 표현해요.\n",
    "\n",
    "서론의 y = Wx + by=Wx+b 속의 bb 가 바로 그 편향 값, 맞습니다!\n",
    "\n",
    "WxWx 에 단순히 더하기 때문에 편향 값은 형태가 (선형변환 결과 차원, ) 인 한 줄짜리 Weight로 정의됩니다. \n",
    "\n",
    "앞서 공부한 예제에서 Dense 클래스 속 use_bias 파라미터를 True 로 바꿔주면 실험해볼 수 있어요! 이 또한 Weight의 파라미터와 동일하게 수많은 데이터를 통해 적합한 값을 찾아가게 된답니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-passage",
   "metadata": {},
   "source": [
    "## Convolution 레이어\n",
    "\n",
    "Linear 레이어를 공부하고 나니 웬만한 데이터는 다 다룰 수 있을 것 같습니다.\n",
    "\n",
    "형태에 맞는 Weight 만 선언해주면 되니까요 !! \n",
    "\n",
    "하지만 다음과 같은 데이터를 만난다면.. 어떻게 하실껀가요??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-horizon",
   "metadata": {},
   "source": [
    "![title](https://d3s0tskafalll9.cloudfront.net/media/images/F-24-selfie.max-800x600.png)\n",
    "\n",
    "<식3>\n",
    "1단계: (1920, 1080, 3) → (1920 x 1080 x 3, )\n",
    "2단계: (6220800, ) x [6220800 x 1 Weight] = (1, )\n",
    "\n",
    "<식 3>에 따르면 아무리 적어도 620만 개의 Parameter가 생성됩니다. \n",
    "\n",
    "게다가 \"손\"이라는 목적이 있음에도 모든 픽셀을 한 줄씩 살펴야하기 때문에 비효율적이죠. 그래서 고안된 것이 Convolution 레이어입니다.\n",
    "\n",
    "Convolution 연산이라는 것은 딥러닝 외적으로도 많이 사용되는 개념입니다. \n",
    "\n",
    "아래 그림을 통해 필터가 이미지와 겹쳐지는 부분의 Convolution 연산을 통해 새롭게 얻어지는 변환된 이미지가 어떻게 생성되는지 확인해 봅시다.\n",
    "\n",
    "![title](https://d3s0tskafalll9.cloudfront.net/media/images/F-24_conv.max-800x600.png)\n",
    "\n",
    "생각보다 단순하죠? 이렇게 연산 과정만 봐서는 어디에 쓰이는지 참 애매해요. \n",
    "\n",
    "하지만 놀랍게도 사진 필터가 Convolution 연산을 활용한 좋은 예라는 사실! 사진을 선명하게 하는 필터와 흐리게 하는 필터 등 다양한 필터들이 Convolution을 위한 행렬로 정의되어 있답니다.\n",
    "\n",
    "이해를 돕기 위해 아래 링크를 방문해 보시면, 다양한 이미지 필터가 주는 Convolution 연산 효과를 시각적으로 확인하실 수 있습니다.\n",
    "\n",
    "[링크](https://aishack.in/tutorials/image-convolution-examples/)\n",
    "\n",
    "![title](https://d3s0tskafalll9.cloudfront.net/media/images/F-24_conv2.max-800x600.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-eligibility",
   "metadata": {},
   "source": [
    "위 그림은 3 x 3 사이즈의 필터(커널)를 선언한 후, 이미지를 필터로 훑으며 각 픽셀을 곱하여 더하는 Convolution 연산을 표현하고 있습니다.\n",
    "\n",
    "이미지와 필터가 겹치는 부분의 값을 서로 곱한 후 그 값을 모두 더하면 새로운 이미지의 한 픽셀값이 되는 것이죠.\n",
    "\n",
    "사진을 흐리게 하는 Blur 필터를 사용했기 때문에 결과가 흐릿해진 것을 확인하실 수 있죠? \n",
    "\n",
    "필터는 다른 말로 커널이라고 부르기도 해요! 이미지를 필터로 훑을 때, 한 칸씩 이동하며 훑을 수도 있지만, 두 칸, 세 칸씩 이동하며 훑을 수도 있습니다. 그것을 결정하는 값을 Stride라고 칭합니다.\n",
    "\n",
    "예리하신 분들은 이쯤에서 Convolution 연산이 입력의 형태를 변형시킨다는 것을 캐치하셨을 겁니다. \n",
    "\n",
    "쉽게 말해, [0, 1, 2, 3, 4] 라는 데이터를 [-1, 0, 1] 이라는 필터로 훑으면 가장 촘촘하게(Stride=1) 이동했을 때 3번밖에 연산을 진행하지 못한다는 거죠. 입력은 (5, ) 형태였지만 출력은 (3, ) 인 [3, 2, 2] 가 됩니다.\n",
    "\n",
    "이를 방지하기 위한 개념이 Padding입니다. 입력의 테두리에 0을 추가해 (ex. [0, 0, 1, 2, 3, 4, 0]) 입력의 형태를 유지할 수 있게 하는 테크닉이죠.\n",
    "\n",
    "Padding에 대해 자세히 알아보고 싶다면 아래 페이지를 방문해보세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beautiful-crown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 이미지 데이터: (64, 1920, 1080, 3)\n",
      "\n",
      "Convolution 결과: (64, 384, 216, 16)\n",
      "Convolution Layer의 Parameter 수: 1200\n",
      "\n",
      "1차원으로 펼친 데이터: (64, 1327104)\n",
      "\n",
      "Linear 결과: (64, 1)\n",
      "Linear Layer의 Parameter 수: 1327104\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 64\n",
    "pic = tf.zeros((batch_size, 1920, 1080, 3))\n",
    "\n",
    "print(\"입력 이미지 데이터:\", pic.shape)\n",
    "conv_layer = tf.keras.layers.Conv2D(filters=16,\n",
    "                                    kernel_size=(5, 5),\n",
    "                                    strides=5,\n",
    "                                    use_bias=False)\n",
    "conv_out = conv_layer(pic)\n",
    "\n",
    "print(\"\\nConvolution 결과:\", conv_out.shape)\n",
    "print(\"Convolution Layer의 Parameter 수:\", conv_layer.count_params())\n",
    "\n",
    "flatten_out = tf.keras.layers.Flatten()(conv_out)\n",
    "print(\"\\n1차원으로 펼친 데이터:\", flatten_out.shape)\n",
    "\n",
    "linear_layer = tf.keras.layers.Dense(units=1, use_bias=False)\n",
    "linear_out = linear_layer(flatten_out)\n",
    "\n",
    "print(\"\\nLinear 결과:\", linear_out.shape)\n",
    "print(\"Linear Layer의 Parameter 수:\", linear_layer.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-reggae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
